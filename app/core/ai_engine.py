# -*- coding: utf-8 -*-
"""
========================================
NetRouter AI - Engine de Intelig√™ncia Artificial
========================================
Este √© o cora√ß√£o inteligente do sistema!

Aqui fazemos a integra√ß√£o com o Google Gemini para:
- Analisar problemas de rede descritos pelo usu√°rio
- Sugerir solu√ß√µes baseadas no contexto do roteador
- Gerar explica√ß√µes sobre comandos e configura√ß√µes
- Responder perguntas sobre troubleshooting

Por que usar Google Gemini?
- √â uma IA muito poderosa e atualizada
- Tem excelente compreens√£o de contexto t√©cnico
- A API √© simples de usar
- Suporta conversas longas com hist√≥rico
========================================
"""

import os
import google.generativeai as genai
from typing import Optional, List, Dict

# Importa as configura√ß√µes do sistema
from app.config import Config


class AIEngine:
    """
    Classe que encapsula toda a l√≥gica de IA do sistema.
    
    Ela √© respons√°vel por:
    1. Configurar e conectar com a API do Gemini
    2. Montar prompts espec√≠ficos para troubleshooting de rede
    3. Processar as respostas da IA
    4. Manter o contexto da conversa
    
    Atributos:
    ----------
    model : GenerativeModel
        Inst√¢ncia do modelo Gemini configurado
    
    chat_history : List[Dict]
        Hist√≥rico da conversa atual (para contexto)
    
    system_prompt : str
        Prompt base que define o comportamento da IA
    
    Exemplo de uso:
    ---------------
    >>> engine = AIEngine()
    >>> resposta = engine.analisar_problema(
    ...     "Roteador n√£o responde a ping",
    ...     fabricante="cisco",
    ...     versao="ios-xe-17"
    ... )
    >>> print(resposta)
    """
    
    def __init__(self):
        """
        Inicializa a engine de IA.
        
        Configura a API do Gemini e prepara o modelo para uso.
        Se a API key n√£o estiver configurada, avisa mas n√£o quebra.
        """
        # Pega a API key das configura√ß√µes
        self.api_key = Config.GOOGLE_API_KEY
        
        # Inicializa como None - ser√° configurado se tiver API key
        self.model = None
        self.chat = None
        
        # Hist√≥rico de mensagens para manter contexto
        self.chat_history: List[Dict] = []
        
        # Prompt do sistema - define a "personalidade" da IA
        # Isso √© MUITO importante para a qualidade das respostas
        self.system_prompt = self._criar_system_prompt()
        
        # Tenta configurar o Gemini
        if self.api_key:
            self._configurar_gemini()
        else:
            print("‚ö†Ô∏è AVISO: API Key do Google n√£o configurada!")
            print("   O sistema funcionar√°, mas sem recursos de IA.")
            print("   Configure GOOGLE_API_KEY no arquivo .env")
    
    def _configurar_gemini(self):
        """
        Configura a conex√£o com a API do Google Gemini.
        
        Este m√©todo √© chamado no __init__ se tivermos API key.
        Configura o modelo e as op√ß√µes de gera√ß√£o de texto.
        """
        try:
            # Configura a biblioteca com nossa API key
            genai.configure(api_key=self.api_key)
            
            # Configura√ß√µes de gera√ß√£o - controla como a IA responde
            generation_config = {
                # Temperatura: 0 = mais preciso, 1 = mais criativo
                # Para troubleshooting, queremos precis√£o!
                "temperature": 0.3,
                
                # Top P: diversidade das respostas
                "top_p": 0.8,
                
                # Top K: quantas palavras considerar
                "top_k": 40,
                
                # M√°ximo de tokens na resposta
                "max_output_tokens": 2048,
            }
            
            # Configura√ß√µes de seguran√ßa - relaxamos um pouco
            # porque estamos falando de termos t√©cnicos que podem
            # ser mal interpretados (como "kill process", "terminate", etc)
            safety_settings = [
                {
                    "category": "HARM_CATEGORY_HARASSMENT",
                    "threshold": "BLOCK_ONLY_HIGH"
                },
                {
                    "category": "HARM_CATEGORY_HATE_SPEECH",
                    "threshold": "BLOCK_ONLY_HIGH"
                },
                {
                    "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    "threshold": "BLOCK_ONLY_HIGH"
                },
                {
                    "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                    "threshold": "BLOCK_ONLY_HIGH"
                }
            ]
            
            # Cria o modelo com as configura√ß√µes
            self.model = genai.GenerativeModel(
                model_name=Config.GEMINI_MODEL,
                generation_config=generation_config,
                safety_settings=safety_settings
            )
            
            # Inicia uma sess√£o de chat para manter contexto
            self.chat = self.model.start_chat(history=[])
            
            print("‚úÖ Engine de IA configurada com sucesso!")
            
        except Exception as e:
            print(f"‚ùå Erro ao configurar Gemini: {str(e)}")
            self.model = None
    
    def _criar_system_prompt(self) -> str:
        """
        Cria o prompt do sistema que define o comportamento da IA.
        
        Esse prompt √© FUNDAMENTAL para a qualidade das respostas.
        Ele ensina a IA a:
        - Se comportar como um engenheiro de redes experiente
        - Dar respostas pr√°ticas e objetivas
        - Considerar o fabricante e vers√£o espec√≠ficos
        - Formatar as respostas de forma clara
        
        Retorna:
        --------
        str
            O prompt do sistema completo
        """
        # Prompt bem detalhado para obter respostas de qualidade
        return """Voc√™ √© um Engenheiro de Redes S√™nior especializado em troubleshooting e configura√ß√£o de roteadores enterprise.

EXPERTISE:
- Cisco (IOS, IOS-XE, IOS-XR, NX-OS)
- Nokia Service Router (SR OS)
- Fortinet FortiGate (FortiOS)
- Huawei (VRP, CloudEngine, USG)

COMPORTAMENTO:
1. Seja DIRETO e PR√ÅTICO nas respostas
2. Sempre considere o fabricante e vers√£o espec√≠ficos informados
3. Forne√ßa comandos EXATOS que podem ser copiados e colados
4. Explique o que cada comando faz em coment√°rios
5. Sugira comandos de verifica√ß√£o ap√≥s corre√ß√µes
6. Alerte sobre riscos ou impactos das a√ß√µes

FORMATO DAS RESPOSTAS:
- Use markdown para formata√ß√£o
- Separe comandos em blocos de c√≥digo
- Liste passos numerados quando apropriado
- Destaque avisos importantes com ‚ö†Ô∏è
- Use ‚úÖ para confirma√ß√µes e ‚ùå para alertas

IMPORTANTE:
- Nunca invente comandos que n√£o existem
- Se n√£o souber algo espec√≠fico de uma vers√£o, avise
- Priorize seguran√ßa - sugira backups antes de mudan√ßas
- Considere impactos em ambiente de produ√ß√£o"""
    
    def analisar_problema(
        self,
        descricao_problema: str,
        fabricante: str = "",
        versao: str = "",
        logs: str = "",
        contexto_adicional: str = ""
    ) -> Dict:
        """
        Analisa um problema de rede e retorna diagn√≥stico + solu√ß√µes.
        
        Esta √© a fun√ß√£o principal de troubleshooting!
        Ela monta um prompt detalhado com todas as informa√ß√µes
        e pede para a IA analisar e sugerir solu√ß√µes.
        
        Par√¢metros:
        -----------
        descricao_problema : str
            Descri√ß√£o do problema pelo usu√°rio
            Ex: "BGP session n√£o estabelece com peer"
        
        fabricante : str
            Fabricante do equipamento (cisco, nokia, fortigate, huawei)
        
        versao : str
            Vers√£o do sistema operacional
            Ex: "ios-xe-17" ou "fortios-74"
        
        logs : str
            Logs ou outputs de comandos relevantes (opcional)
        
        contexto_adicional : str
            Qualquer info extra √∫til (topologia, hist√≥rico, etc)
        
        Retorna:
        --------
        Dict
            Dicion√°rio com:
            - sucesso: bool
            - analise: str (resposta da IA)
            - erro: str (se houver erro)
        
        Exemplo:
        --------
        >>> resultado = engine.analisar_problema(
        ...     "Interface GigabitEthernet0/0 est√° flapping",
        ...     fabricante="cisco",
        ...     versao="ios-xe-17"
        ... )
        """
        # Se n√£o temos modelo configurado, retorna erro amig√°vel
        if not self.model:
            return {
                "sucesso": False,
                "analise": "",
                "erro": "IA n√£o configurada. Verifique a API key."
            }
        
        try:
            # Monta o prompt completo para an√°lise
            prompt = self._montar_prompt_analise(
                descricao_problema,
                fabricante,
                versao,
                logs,
                contexto_adicional
            )
            
            # Envia para a IA e aguarda resposta
            # Usamos o chat para manter contexto entre mensagens
            resposta = self.chat.send_message(prompt)
            
            # Adiciona ao hist√≥rico local
            self.chat_history.append({
                "role": "user",
                "content": descricao_problema
            })
            self.chat_history.append({
                "role": "assistant",
                "content": resposta.text
            })
            
            return {
                "sucesso": True,
                "analise": resposta.text,
                "erro": ""
            }
            
        except Exception as e:
            # Se der erro, retorna info √∫til para debug
            return {
                "sucesso": False,
                "analise": "",
                "erro": f"Erro ao analisar: {str(e)}"
            }
    
    def _montar_prompt_analise(
        self,
        problema: str,
        fabricante: str,
        versao: str,
        logs: str,
        contexto: str
    ) -> str:
        """
        Monta o prompt completo para an√°lise de problema.
        
        Aqui organizamos todas as informa√ß√µes em um formato
        que a IA consiga entender bem e dar respostas relevantes.
        """
        # Come√ßa com o contexto do equipamento
        prompt_parts = [self.system_prompt, "\n\n---\n\n"]
        
        # Adiciona info do fabricante se informado
        if fabricante:
            info_fab = Config.FABRICANTES_SUPORTADOS.get(fabricante, {})
            nome_fab = info_fab.get('nome', fabricante.title())
            prompt_parts.append(f"**Equipamento:** {nome_fab}\n")
        
        # Adiciona vers√£o se informada
        if versao and fabricante:
            versoes = Config.FABRICANTES_SUPORTADOS.get(fabricante, {}).get('versoes', {})
            info_versao = versoes.get(versao, {})
            nome_versao = info_versao.get('nome', versao)
            prompt_parts.append(f"**Vers√£o:** {nome_versao}\n")
        
        # Adiciona o problema principal
        prompt_parts.append(f"\n**PROBLEMA RELATADO:**\n{problema}\n")
        
        # Adiciona logs se fornecidos
        if logs:
            prompt_parts.append(f"\n**LOGS/OUTPUT:**\n```\n{logs}\n```\n")
        
        # Adiciona contexto extra
        if contexto:
            prompt_parts.append(f"\n**CONTEXTO ADICIONAL:**\n{contexto}\n")
        
        # Instru√ß√£o final
        prompt_parts.append("""
---

Por favor, analise o problema acima e forne√ßa:
1. **Poss√≠veis Causas** - Lista das causas mais prov√°veis
2. **Comandos de Diagn√≥stico** - Comandos para investigar (espec√≠ficos para o fabricante/vers√£o)
3. **Solu√ß√£o Recomendada** - Passos para resolver o problema
4. **Verifica√ß√£o** - Como confirmar que o problema foi resolvido
""")
        
        return "".join(prompt_parts)
    
    def gerar_script_ia(
        self,
        descricao_tarefa: str,
        fabricante: str,
        versao: str,
        tipo_script: str = "configuracao"
    ) -> Dict:
        """
        Usa a IA para gerar scripts de configura√ß√£o.
        
        Al√©m dos templates pr√©-definidos, podemos pedir para
        a IA gerar scripts customizados para tarefas espec√≠ficas.
        
        Par√¢metros:
        -----------
        descricao_tarefa : str
            O que o script deve fazer
            Ex: "Configurar OSPF na interface GigabitEthernet0/0"
        
        fabricante : str
            Fabricante do roteador
        
        versao : str
            Vers√£o do sistema
        
        tipo_script : str
            Tipo de script: configuracao, backup, diagnostico, rollback
        
        Retorna:
        --------
        Dict
            - sucesso: bool
            - script: str (o script gerado)
            - explicacao: str (o que cada parte faz)
            - erro: str (se houver)
        """
        if not self.model:
            return {
                "sucesso": False,
                "script": "",
                "explicacao": "",
                "erro": "IA n√£o configurada."
            }
        
        try:
            # Monta prompt espec√≠fico para gera√ß√£o de scripts
            prompt = f"""{self.system_prompt}

---

**TAREFA:** Gerar script de {tipo_script}

**Equipamento:** {fabricante.title()}
**Vers√£o:** {versao}

**O que o script deve fazer:**
{descricao_tarefa}

---

Por favor, gere:
1. **Script completo** pronto para copiar e colar
2. **Coment√°rios** explicando cada se√ß√£o/comando
3. **Avisos** sobre riscos ou pr√©-requisitos
4. **Comandos de verifica√ß√£o** para confirmar que funcionou

Formate o script em bloco de c√≥digo apropriado.
"""
            
            resposta = self.chat.send_message(prompt)
            
            return {
                "sucesso": True,
                "script": resposta.text,
                "explicacao": "",  # J√° est√° inclu√≠da na resposta
                "erro": ""
            }
            
        except Exception as e:
            return {
                "sucesso": False,
                "script": "",
                "explicacao": "",
                "erro": f"Erro ao gerar script: {str(e)}"
            }
    
    def chat_livre(self, mensagem: str) -> Dict:
        """
        Permite conversa livre com a IA sobre temas de rede.
        
        Usado pelo chat do dashboard para perguntas gerais.
        Mant√©m o contexto da conversa.
        
        Par√¢metros:
        -----------
        mensagem : str
            Mensagem do usu√°rio
        
        Retorna:
        --------
        Dict
            - sucesso: bool
            - resposta: str
            - erro: str
        """
        if not self.model:
            return {
                "sucesso": False,
                "resposta": "",
                "erro": "IA n√£o configurada. Verifique a API key no arquivo .env"
            }
        
        try:
            # Adiciona contexto se for a primeira mensagem
            if not self.chat_history:
                mensagem_completa = f"{self.system_prompt}\n\n---\n\nUsu√°rio: {mensagem}"
            else:
                mensagem_completa = mensagem
            
            resposta = self.chat.send_message(mensagem_completa)
            
            # Atualiza hist√≥rico
            self.chat_history.append({"role": "user", "content": mensagem})
            self.chat_history.append({"role": "assistant", "content": resposta.text})
            
            return {
                "sucesso": True,
                "resposta": resposta.text,
                "erro": ""
            }
            
        except Exception as e:
            return {
                "sucesso": False,
                "resposta": "",
                "erro": f"Erro no chat: {str(e)}"
            }
    
    def limpar_historico(self):
        """
        Limpa o hist√≥rico de conversa.
        
        √ötil quando queremos come√ßar um novo troubleshooting
        sem o contexto da conversa anterior.
        """
        self.chat_history = []
        
        # Reinicia a sess√£o de chat tamb√©m
        if self.model:
            self.chat = self.model.start_chat(history=[])
        
        print("üßπ Hist√≥rico de conversa limpo!")
    
    def obter_historico(self) -> List[Dict]:
        """
        Retorna o hist√≥rico da conversa atual.
        
        Retorna:
        --------
        List[Dict]
            Lista de mensagens com role e content
        """
        return self.chat_history.copy()
